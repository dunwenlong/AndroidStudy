<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <style type="text/css">
            h1 {
                counter-reset: one;  /* 创建一个计数器 */
            }
    
            h2 {
                counter-reset: two;
            }
            h2:before {
                counter-increment: one; /* 自动将计数器加 1 */
                content: counter(one) ". "; /* 获取计数器值，把它填写在 content 中 */
            }
    
            h3 {
                counter-reset: three;
            }
            h3:before {
                counter-increment: two;
                content: counter(one) "." counter(two) ". ";
            }
    
            h4 {
                counter-reset: four;
            }
            h4:before {
                counter-increment: three;
                content: counter(one) "." counter(two) "." counter(three) ". ";
            }
    
            h5 {
                counter-reset: five;
            }
            h5:before {
                counter-increment: four;
                content: counter(one) "." counter(two) "." counter(three) "." counter(four) ". ";
            }
        </style>
    </head>
<body style="padding-left: 1cm;">
    <h1 style="text-align: center;">java锁相关知识</h1>
    <h2>线程和进程的区别</h2>
    <p>
        1、进程是资源分配的最小单位，线程是程序执行的最小单位（资源调度的最小单位）</br>
        2、进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。
        而线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。</br>
        3、线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（IPC)进行。不过如何处理好同步与互斥是编写多线程程序的难点。</br>
        4、但是多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间</br>
        进程：无名管道、有名管道、信号、共享内存、消息队列、信号量</br>
        进程：互斥量、读写锁、自旋锁、线程信号、条件变量    </br>
    </p>
    <h3>Thread的几个重要方法</h3>
    我们先了解一下Thread的几个重要方法。a、start()方法，调用该方法开始执行该线程；b、stop()方法，调用该方法强制结束该线程执行；c、join方法，调用该方法等待该线程结束。d、sleep()方法，调用该方法该线程进入等待。e、run()方法，调用该方法直接执行线程的run()方法，但是线程调用start()方法时也会运行run()方法，区别就是一个是由线程调度运行run()方法，一个是直接调用了线程中的run()方法！！
    看到这里，可能有些人就会问啦，那wait()和notify()呢？要注意，其实wait()与notify()方法是Object的方法，不是Thread的方法！！同时，wait()与notify()会配合使用，分别表示线程挂起和线程恢复。
    这里还有一个很常见的问题，顺带提一下：wait()与sleep()的区别，简单来说wait()会释放对象锁而sleep()不会释放对象锁。这些问题有很多的资料，不再赘述。
    <h3>线程状态</h3>
    新建状态：新建线程对象，并没有调用start()方法之前</br>
    就绪状态：调用start()方法之后线程就进入就绪状态，但是并不是说只要调用start()方法线程就马上变为当前线程，在变为当前线程之前都是为就绪状态。值得一提的是，线程在睡眠和挂起中恢复的时候也会进入就绪状态哦。</br>
    运行状态：线程被设置为当前线程，开始执行run()方法。就是线程进入运行状态</br>
    阻塞状态：线程被暂停，比如说调用sleep()方法后线程就进入阻塞状态</br>
    死亡状态：线程执行结束</br>
    <h3>锁类型</h3>
    可重入锁：在执行对象中所有同步方法不用再次获得锁</br>
    可中断锁：在等待获取锁过程中可中断</br>
    公平锁： 按等待获取锁的线程的等待时间进行获取，等待时间长的具有优先获取锁权利</br>
    读写锁：对资源读取和写入的时候拆分为2部分处理，读的时候可以多线程一起读，写的时候必须同步地写</br>
    锁的底层主要靠volatile和CAS操作实现
    <h2>读写锁</h2>
    <p>
        ReadWriteLock 同lock一样也是一个接口，提供了ReadLock 和 WriteLock两种锁的操作机制，一个是只读的锁，一个是写锁。读锁可以在没有写锁的时候被多个线程同时持有，写锁是独占的。一个获得了读锁的线程必须能够看到前一个释放的写锁更新的内容。
        理论上，读写锁比互斥锁允许对于共享数据更大程度的并发。与互斥锁相比，读写锁是否能够提高性能取决于读写数据的频率、读取和写入操作的持续时间、以及读线程和写线程之间的竞争。
    </p>
    <h3>使用场景</h3>
    <p>
        假设你的程序中涉及到对一些共享资源的读和写操作，且写操作没有读操作那么频繁。例如，最初填充有数据，然后很少修改的集合，同时频繁搜索（例如某种目录）是使用读写锁的理想候选项。在没有写操作的时候，两个线程同时读一个资源没有任何问题，所以应该允许多个线程能在同时读取共享资源。但是如果有一个线程想去写这些共享资源，就不应该再有其它线程对该资源进行读或写。这就需要一个读/写锁来解决这个问题。
    </p>
    <h3>互斥原则</h3>
    <p>
        读读能共存，读写不能共存，写写不能共存
    </p>
    <h3>公平锁</h3>
    <p>
        在锁上等待时间最长的线程将获得锁的使用权
    </p>


    <h2> 死锁 </h2>
    <h3>死锁</h3>
    <p>
        多个线程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。死锁是两个或更多线程阻塞着等待其它处于死锁状态的线程所持有的锁。。死锁通常发生在多个线程同时但以不同的顺序请求同一组锁的时候。例如，如果线程1锁住了A，然后尝试对B进行加锁，同时线程2已经锁住了B，接着尝试对A进行加锁，这时死锁就发生了。线程1永远得不到B，线程2也永远得不到A，并且它们永远也不会知道发生了这样的事情。为了得到彼此的对象（A和B），它们将永远阻塞下去。这种情况就是一个死锁。
    </p>


    <h2> 可重入锁 </h2>
    <p>
        synchronized和ReenTrantLock
        什么是 “可重入”，可重入就是说某个线程已经获得某个锁，可以再次获取锁而不会出现死锁。<br></br>
        ReenTrantLock独有的能力：
        1 . ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。

        2. ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。

        3. ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。
    </p>
    <h3> 区别 </h3>
    <p>
        这两种方式最大区别就是对于Synchronized来说，它是java语言的关键字，是原生语法层面的互斥，需要jvm实现。而ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try/finally语句块来完成</br>
        便利性：很明显Synchronized的使用比较方便简洁，并且由编译器去保证锁的加锁和释放，而ReenTrantLock需要手工声明来加锁和释放锁，为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁。      
    </p>
    <h3>性能区别</h3>
    <p>
        在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。
    </p>

    <h3>Synchronized</h3>
        在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。</br>
        JDK1.6,1.7的优化</br>
        <b>1、线程自旋和适应性自旋</br></b>
        我们知道，java’线程其实是映射在内核之上的，线程的挂起和恢复会极大的影响开销。并且jdk官方人员发现，很多线程在等待锁的时候，在很短的一段时间就获得了锁，所以它们在线程等待的时候，并不需要把线程挂起，而是让他无目的的循环，一般设置10次。这样就避免了线程切换的开销，极大的提升了性能。
        而适应性自旋，是赋予了自旋一种学习能力，它并不固定自旋10次一下。他可以根据它前面线程的自旋情况，从而调整它的自旋，甚至是不经过自旋而直接挂起。</br>
        <b>2、锁消除</br></b>
        什么叫锁消除呢？就是把不必要的同步在编译阶段进行移除。
        那么有的小伙伴又迷糊了，我自己写的代码我会不知道这里要不要加锁？我加了锁就是表示这边会有同步呀？
        并不是这样，这里所说的锁消除并不一定指代是你写的代码的锁消除</br>
        <b>3、锁粗化</br></b>
        <b>4、轻量级锁</br></b>
        <b>5、偏向锁</br></b>

        Synchronized的作用
        在JDK1.5之前都是使用synchronized关键字保证同步的，Synchronized的作用相信大家都已经非常熟悉了；
        它可以把任意一个非NULL的对象当作锁。
        作用于方法时，锁住的是对象的实例(this)；
        当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen（jdk1.8则是metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程；
        synchronized作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。

    <h3>ReenTrantLock实现的原理</h3>
        简单来说，ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。

    <h2>偏向锁</h2>
    偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。 
    如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。
    <h3>偏向锁的适用场景</h3>
    始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作； 
    在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用；


    <h2> 轻量级自旋锁 </h2>
    自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。但是线程自旋是需要消耗cup的，说白了就是让cup在做无用功，如果一直获取不到锁，那线程也不能一直占用cup自旋做无用功，所以需要设定一个自旋等待的最大时间。如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。

    <h3>自旋锁的优缺点</h3>
    自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次上下文切换！但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用cpu做无用功，占着XX不XX，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要cup的线程又不能获取到cpu，造成cpu的浪费。所以这种情况下我们要关闭自旋锁；

    <h3>自旋锁时间阈值</h3>
    自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。因此自旋的周期选的额外重要！
    JVM对于自旋周期的选择，jdk1.5这个限度是一定的写死的，在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间，同时JVM还针对当前CPU的负荷情况做了较多的优化.如果平均负载小于CPUs则一直自旋,如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞,如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞,如果CPU处于节电模式则停止自旋，自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差），自旋时会适当放弃线程优先级之间的差异。


    <h2>独占锁</h2>
    独占锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排他锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和 JUC中Lock的实现类就是互斥锁。
    <h2>共享锁</h2>
    共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。
    <h2>CAS操作</h2>
    CAS：Compare and Swap，即比较再交换。
    jdk5增加了并发包java.util.concurrent.*,其下面的类使用CAS算法实现了区别于synchronouse同步锁的一种乐观锁。JDK 5之前Java语言是靠synchronized关键字保证同步的，这是一种独占锁，也是是悲观锁。
    <h3>介绍</h3>
    对CAS的理解，CAS是一种无锁算法，CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。</br>
    do{</br>
        备份旧数据；</br>
        基于旧数据构造新数据；</br>
        }while(!CAS( 内存地址，备份的旧数据，新数据 ))</br>
    （通俗的解释是：CPU去更新一个值，但如果想改的值不再是原来的值，操作就失败，因为很明显，有其它操作先改变了这个值。）
    就是指当两者进行比较时，如果相等，则证明共享数据没有被修改，替换成新值，然后继续往下运行；如果不相等，说明共享数据已经被修改，放弃已经所做的操作，然后重新执行刚才的操作。容易看出 CAS 操作是基于共享数据不会被修改的假设，采用了类似于数据库的commit-retry 的模式。当同步冲突出现的机会很少时，这种假设能带来较大的性能提升。
    <h3>ABA问题</h3>
    就是说一个线程把数据A变为了B，然后又重新变成了A。此时另外一个线程读取的时候，发现A没有变化，就误以为是原来的那个A。这就是有名的ABA问题</br>
    ABA解决方案:加版本号
    AtomicMarkableReference 可以解决,使用boolean变量——表示引用变量是否被更改过,不关心中间变量变化了几次
    AtomicStampedReference 也可以解决,其中的构造方法中initialStamp（时间戳）用来唯一标识引用变量,引用变量中途被更改了几次
    <h2> Volatile关键字 </h2>
    <p>
    大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。
    也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其 中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。</br>
    </p>
    所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。</br>
    一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：
　　1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。
    2）禁止进行指令重排序。
    <p>
        第一：使用volatile关键字会强制将修改的值立即写入主存；
        第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1
        L2缓存中对应的缓存行无效）；
        第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。</br>
        可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。
    </p>
</body>
</html>